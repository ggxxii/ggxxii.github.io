<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<!-- saved from url=(0033)http://home.ustc.edu.cn/~canwang/ -->
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" class="gr__cs_toronto_edu"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link rel="shortcut icon" href="http://www.cs.toronto.edu/~rjliao/imgs/myIcon.jpg">

<meta name="keywords" content="Yufei Liu, CG, Computer Vision, Shanghai Film Academy">
<meta name="description" content="Yufei Liu&#39;s home page">
<link rel="stylesheet" href="./Can Wang_files/jemdoc.css" type="text/css">
<title>Yufei Liu</title>

</head>
<body data-gr-c-s-loaded="true" data-new-gr-c-s-check-loaded="14.1006.0" data-gr-ext-installed="">

<div id="layout-content" style="margin-top:25px">

<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">
					<!-- <h1>Yufei Liu &nbsp; <img src="./Can Wang_files/can_chinese.png" height="45px" style="margin-bottom:-10px"></h1><h1> -->
                    <h1>Yufei Liu &nbsp <h1>
                    </h1></div>

				<h3>Phd Candidate</h3>
			  <p>
					Shanghai Film Academy<br>
					Shanghai University<br>
					Shanghai, China <br>
          <br>
				<!-- Email:  -->
				<!-- <br>Blog: <a href="https://blog.csdn.net/cassiePython">https://blog.csdn.net/cassiePython</a> -->

				<br>Github: <a href="https://github.com/ggxxii/">https://github.com/ggxxii/</a></p>
			</td><td>
				<!-- <img src="./Can Wang_files/me_pencil.png" border="0" width="200"><br> -->
			</td>
		</tr><tr>
	</tr></tbody>
</table>

<!-- <h2>Biography</h2>
<p>
  I am currently a third-year Phd Candidate. My advisor is <a href="https://liaojing.github.io/html/index.html">Prof. Jing Liao</a>. During my Phd study, I am co-supervised by
	<a href="https://mlchai.com/">Menglei Chai</a>, <a href="https://mingminghe.com/">Mingming He</a>, and <a href="https://www.dongdongchen.bid/">Dongdong Chen</a>. I was a research intern at Meta Reality Lab, Codec Avatar team, worked with 
	<a href="https://scholar.google.com/citations?user=FfaVfjIAAAAJ&hl=en">Kaiwen Guo</a>, <a href="https://scholar.google.com/citations?user=RaYwRQ8AAAAJ&hl=en">Yuhua Chen</a>, and <a href="https://jingyunliang.github.io/">Jingyun Liang</a>. 
</p>

<p>I have broad research interests in machine learning, computer vision, and graphics. Recently I am focusing on neural implicit fields and diffusion models. </p>

<h2>Publications</h2>
<ul>
  <li>
    <a href="https://arxiv.org/pdf/2305.11588.pdf">Text2NeRF: Text-Driven 3D Scene Generation with Neural Radiance Fields,<br></a>
    Jingbo Zhang, Xiaoyu Li, Ziyu Wan, <b>Can Wang</b>, Jing Liao<br>
    <em>arXiv</em>, 2023. <a href="https://eckertzhang.github.io/Text2NeRF.github.io/">[Project]</a><br>
  </li>
  <li>
    <a href="https://arxiv.org/abs/2303.17606">AvatarCraft: Transforming Text into Neural Human Avatars with Parameterized Shape and Pose Control,<br></a>
    Ruixiang Jiang, <b>Can Wang</b>, Jingbo Zhang, Menglei Chai, Mingming He, Dongdong Chen, Jing Liao<br>
    <em>International Conference on Computer Vision</em> (<b>ICCV</b>), 2023. <a href="https://avatar-craft.github.io/">[Project]</a><br>
  </li>
	
  <li>
    <a href="https://arxiv.org/abs/2208.05751">NeRF-Art: Text-Driven Neural Radiance Fields Stylization,<br></a>
    <b>Can Wang</b>, Ruixiang Jiang, Menglei Chai, Mingming He, Dongdong Chen, Jing Liao<br>
    <em>IEEE Transactions on Visualization and Computer Graphics</em>, 2023. <a href="https://cassiepython.github.io/nerfart/">[Project]</a><br>
  </li>

  <li>
    <a href="https://arxiv.org/abs/2208.05751">FDNeRF: Few-shot Dynamic Neural Radiance Fields for Face Reconstruction and Expression Editing,<br></a>
    Jingbo Zhang, Xiaoyu Li, Ziyu Wan, <b>Can Wang</b>, Jing Liao<br>
    <em>ACM SIGGRAPH Conference in Asia</em> (<b>SIGGRAPH Asia</b>), 2022. <a href="https://fdnerf.github.io/">[Project]</a><br>
  </li>
  
  <li>
    <a href="https://arxiv.org/abs/2112.05139">CLIP-NeRF: Text-and-Image Driven Manipulation of Neural Radiance Fields,<br></a>
    <b>Can Wang</b>, Menglei Chai, Mingming He, Dongdong Chen, Jing Liao<br>
    <em>Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2022. <a href="https://cassiepython.github.io/clipnerf/">[Project]</a><br>
  </li>
	
  <li>
    <a href="">Deep Portrait Lighting Enhancement with 3D Guidance,<br></a>
    Fangzhou Han*, <b>Can Wang*</b>, Hao Du, Jing Liao [*Equal Contribution]<br> 
    <em>Eurographics Symposium on Rendering, selected to CGF Track</em> (<b>EGSR & CGF</b>), 2021. <a href="https://cassiepython.github.io/egsr/index.html">[Project]</a><br>
  </li>
   
  <li>
    <a href="https://arxiv.org/abs/2104.11228">Cross-Domain and Disentangled Face Manipulation with 3D Guidance,<br></a>
    <b>Can Wang</b>, Menglei Chai, Mingming He, Dongdong Chen, Jing Liao<br>
    <em>IEEE Transactions on Visualization and Computer Graphics</em>, 2021. <a href="https://cassiepython.github.io/cddfm3d/index">[Project]</a><br>
  </li>
  
  <li>
    <a href="">Dual Learning for Joint Facial Landmark Detection and Action Unit Recognition,<br></a>
    Shangfei Wang, Yanan Chang, <b>Can Wang</b><br>
    <em>IEEE Transactions on Affective Computing</em> (<b>IEEE</b>), 2021. <br>
  </li>

  <li>
    <a href="https://dl.acm.org/citation.cfm?id=3240613">Personalized Multiple Facial Action Unit Recognition through Generative Adversarial Recognition Network,<br></a>
    <b>Can Wang</b>, Shangfei Wang<br>
    <em>ACM Multimedia</em> (<b>ACMMM</b>), 2018. <br>
  </li>

  <li>
    <a href="https://ieeexplore.ieee.org/abstract/document/8697096">Video Affective Content Analysis by Exploring Domain Knowledge,<br></a>
    Shangfei Wang, <b>Can Wang</b>, Tanfang Chen, Yaxin Wang, Yangyang Shu, Qiang Ji<br>
    <em>IEEE Transactions on Affective Computing</em> (<b>IEEE</b>), 2019. <br>
  </li>

  <li>
    <a href="https://dl.acm.org/doi/10.1145/3343031.3350872">Identity- and Pose-Robust Facial Expression Recognition through Adversarial Feature Learning,<br></a>
    <b>Can Wang</b>, Shangfei Wang, Guang Liang<br>
    <em>ACM Multimedia</em> (<b>ACMMM</b>), 2019. <br>
  </li>

  <li>
    <a href="https://ieeexplore.ieee.org/abstract/document/8756621">Integrating Facial Images, Speeches and Time for Empathy Prediction,<br></a>
    Shi Yin, Yonggan Fu, <b>Can Wang</b>, Runlong Wu, Heyan Ding, Shangfei Wang<br>
    <em>Automatic Face &amp; Gesture Recognition </em> (<b>FG</b>), 2019. <a href="https://github.com/tilmto/OMG_DAE">[Code]</a><br>
  </li>

  <li>
    <a href="https://mp.weixin.qq.com/s?__biz=MzI2Nzk3NDk4NQ==&amp;mid=2247484768&amp;idx=1&amp;sn=133f34f77156a90d2a63e8925efeda71&amp;chksm=eaf7e546dd806c50a4d19253992cd8508ad86259ca5a173a313991a34d5f6f1596b46fee7a18&amp;mpshare=1&amp;scene=23&amp;srcid=&amp;sharer_sharetime=1580482529703&amp;sharer_shareid=3f6fc2054bfe16c4377e2b842e5aeec1#rd">面部表情分析,<br></a>
    Shangfei Wang, <b>Can Wang</b><br>
    <em>CAA-PRMI专委会通讯2019年第4期(总第8期)约稿 </em> (<b>中国自动化学会</b>), 2019. <br>
  </li>

  <li>
    <a href="https://www.sciencedirect.com/science/article/pii/S0925231220310766">CardioID: learning to identification from electrocardiogram data,<br></a>
    Shenda Hong, <b>Can Wang</b>, Zhaoji Fu<br>
    <em>Neurocomputing </em>, 2020. <a href="https://github.com/cassiePython/CardioID">[Code]</a><br>
  </li>

  <li>
    <a href="http://home.ustc.edu.cn/~canwang/">Exploiting Multi-Emotion Relations at Feature and Label Levels for Emotion Tagging,<br></a>
    Zhiwei Xu, Shangfei Wang, <b>Can Wang</b><br>
    <em>ACM Multimedia</em> (<b>ACMMM</b>), 2020. <br>
  </li>

  <li>
    <a href="https://arxiv.org/abs/2007.05932">Pose-aware Adversarial Domain Adaptation for Personalized Facial Expression Recognition,<br></a>
    Guang Liang, Shangfei Wang, <b>Can Wang</b><br>
    <em>arXiv.org</em>, 2020. <br>
  </li>

  <li>
    <a href="https://www.sciencedirect.com/science/article/pii/S0169260720316801?via%3Dihub">Gated Temporal Convolutional Neural Network and Expert Features for Diagnosing and Explaining Physiological Time Series: A Case Study on Heart Rates,<br></a>
    Shenda Hong, <b>Can Wang</b>, Zhaoji Fu<br>
    <em>Computer Methods and Programs in Biomedicine </em>, 2020. <br>
  </li>
	
  <li>
    <a href="https://ieeexplore.ieee.org/document/9666974/keywords#keywords">Pose-Invariant Facial Expression Recognition,<br></a>
    Guang Liang, Shangfei Wang, <b>Can Wang</b><br>
    <em>Automatic Face &amp; Gesture Recognition </em> (<b>FG</b>), 2021. <br>
  </li>

  <li>
    <a href="https://www.sciencedirect.com/science/article/abs/pii/S0167865522000629?via%3Dihub">HITS: Binarizing Physiological Time Series with Deep Hashing Neural Network,<br></a>
    Zhaoji Fu, <b>Can Wang</b>, Guodong Wei, Wenrui Zhang, Shaofu Du, Shenda Hong<br>
    <em>Pattern Recognition Letters </em>, 2022. <br>
  </li>


</ul>

<h2>Employment</h2>
  <ul>
    <li>Internship in the Institute of Electrics, Chinese Academy of Sciences, 6/2017-9/2017. </li>
    <li>Internship in the Students We-Media Alliance, Baidu,  7/2018-10/2018.</li>
	<li>Internship in the Anhui Heart Voice Medical Technology Limited Company, HeartVoice,  8/2019-8/2020.</li>
  </ul>

<h2>Teaching Assistant</h2>
  <ul>
	<li>Advanced Artificial Intelligence (2019 Winter) </li>
    <li>Introduction to Artificial Intelligence (2019 Spring) </li>
    <li>Pattern Recognition (2018 Winter) </li>
    <li>C Language Programming (2018 Winter) </li>
  </ul>

<h2>Patents</h2>
  <ul>
	<li>基于对抗学习的角度鲁棒的个性化人脸表情识别方法，CN111382684A，Shangfei Wang, <b>Can Wang</b><br> </li>
  </ul>


<h2>Honors &amp; Awards</h2>
<table style="border-spacing:2px">

    <tbody>

        <tr><td><i>Java Programming Contest of Oracle</i>, the Third Prize, 2015.</td></tr>

		<tr><td><i>RoboCup International Competition and Symposium</i>, the Second Prize of China, 2015.</td></tr>

		<tr> <td><i>China Collegiate Programming Contest</i>, the Second Prize of China, 2016.</td></tr>

		<tr> <td><i>Excellent Intern in Chinese Academy of Sciences</i>, 2017.</td></tr>

		<tr> <td><i>The Best Editor Award of Baidu</i>, 2018.</td></tr>

		<tr> <td><i>The second place of 2018 OMG-Empathy Prediction Challenge of IEEE FG conference</i>, <a href="https://www2.informatik.uni-hamburg.de/wtm/omgchallenges/omg_empathy2018_results2018.html#">See more</a>, 2018.</td></tr>

        <tr><td><i>Student Travel Award</i>, ACMMM 2018.</td></tr>
		<tr><td><i>National Scholarship</i>, 2018.</td></tr>
		<tr><td><i>National Scholarship</i>, 2019.</td></tr>
		<tr><td><i>Outstanding graduate in Anhui Province</i>, 2020.</td></tr>
		<tr><td><i>The fourth place of CVPR 2020 EmotionNet Challenge</i>, 2020.</td></tr>
	    	<tr><td><i>Research Tuition Scholarship, City University of Hong Kong</i>, 2022.</td></tr>
	        <tr><td><i>Research Tuition Scholarship, City University of Hong Kong</i>, 2023.</td></tr>


	</tbody>
</table>

<h2>Miscellany</h2>
<p>Hobbies: Erhu, Basketball, Music.<br>
I am a member of Nationalities Music Orchestra of USTC.</p>

<p>Last Updated by Can Wang: Aug. 27 2020</p>
<div id="footer">
	<div id="footer-text"></div>
</div>
</div>
</body></html> -->